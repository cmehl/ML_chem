{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning applied to 0D reactors with multiple dt prediction: NODE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google colab preparation\n",
    "\n",
    "These lines are here to enable Colab running of the tools. We need to perform a git clone in order to have access to python scripts. This needs to be done at each runtime as the clone is lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if use_colab:\n",
    "    !git clone -b cost_course_exercices https://github.com/cmehl/ML_chem.git\n",
    "    \n",
    "    !pip install cantera\n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Create a folder in the root directory\n",
    "    if not os.path.isdir(\"/content/drive/MyDrive/ML_chem_data\"):\n",
    "        !mkdir -p \"/content/drive/MyDrive/ML_chem_data\"\n",
    "    else:\n",
    "        print(\"Folder /content/drive/MyDrive/ML_chem_data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cantera as ct\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchdiffeq as tdf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(\"notebook\")\n",
    "\n",
    "if use_colab:\n",
    "    from ML_chem.chem_ai.cantera_runs import compute_nn_cantera_0D_homo\n",
    "    from ML_chem.chem_ai.utils import get_molar_mass_atomic_matrix\n",
    "    from ML_chem.chem_ai.utils import StandardScaler\n",
    "else:\n",
    "    from chem_ai.cantera_runs import compute_nn_cantera_0D_homo\n",
    "    from chem_ai.utils import get_molar_mass_atomic_matrix\n",
    "    from chem_ai.utils import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the default pytorch precision to double. It slows down a little bit the training but it is the usual standard for CFD reacting flows applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify the device (CPU or GPU) available on the machine. This will be used by pytorch to identify the device on which to train and use the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Running on the GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Running on the CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the folder including the desired database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_colab:\n",
    "    folder = \"/content/drive/MyDrive/ML_chem_data/case_0D_test_multidt\"\n",
    "else:\n",
    "    folder = \"./case_0D_test_multidt_node\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the parameters stored in the json file of the dabatase folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(folder, \"dtb_params.json\"), \"r\") as file:\n",
    "    dtb_params = json.load(file)\n",
    "\n",
    "fuel = dtb_params[\"fuel\"]\n",
    "mech_file = dtb_params[\"mech_file\"]\n",
    "log_transform = dtb_params[\"log_transform\"]\n",
    "threshold = dtb_params[\"threshold\"]\n",
    "p = dtb_params[\"p\"]\n",
    "dt = dtb_params[\"dt\"]\n",
    "\n",
    "print(f\"fuel={fuel}\")\n",
    "print(f\"mech_file={mech_file}\")\n",
    "print(f\"log_transform={log_transform}\")\n",
    "print(f\"threshold={threshold}\")\n",
    "print(f\"p={p}\")\n",
    "print(f\"dt_min={dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaler = joblib.load(os.path.join(folder, \"processed_database\", \"Xscaler.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the training and validation databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(folder, \"processed_database\", \"X_train.npy\"))\n",
    "X_val = np.load(os.path.join(folder, \"processed_database\", \"X_val.npy\"))\n",
    "Y_train = np.load(os.path.join(folder, \"processed_database\", \"Y_train.npy\"))\n",
    "Y_val = np.load(os.path.join(folder, \"processed_database\", \"Y_val.npy\"))\n",
    "\n",
    "dt_array_train = np.load(os.path.join(folder, \"dt_array_train.npy\"))\n",
    "dt_array_val = np.load(os.path.join(folder, \"dt_array_val.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of input and output dimensions, and number of dt values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s_train = X_train.shape[0]\n",
    "n_s_val = X_val.shape[0]\n",
    "\n",
    "n_in = X_train.shape[1]\n",
    "n_out = Y_train.shape[1]\n",
    "nb_dt = Y_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas = ct.Solution(mech_file)\n",
    "A_element = get_molar_mass_atomic_matrix(gas.species_names, fuel, True)\n",
    "print(A_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first method, which we could qualify as brute force, we add *dt* as an input of the network. \n",
    "\n",
    "We first need to prepare datasets so that we have the list of input and corresponding outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integration times are here fixed for all samples, to ease the NeuralODE integration. We just select the first row of *dt_array_train* for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_max = 2.0e-6\n",
    "\n",
    "integration_times = dt_array_train[0,:]\n",
    "# integration_times = integration_times/dt_max\n",
    "\n",
    "integration_times = [0,dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float64)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float64)\n",
    "Y_val = torch.tensor(Y_val, dtype=torch.float64)\n",
    "\n",
    "integration_times = torch.tensor(integration_times, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaler_mean = torch.from_numpy(Xscaler.mean)\n",
    "Xscaler_std = torch.from_numpy(Xscaler.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_element = torch.tensor(A_element, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "Y_val = Y_val.to(device)\n",
    "\n",
    "# dt_array_train = dt_array_train.to(device)\n",
    "# dt_array_val = dt_array_val.to(device)\n",
    "\n",
    "Xscaler_mean = Xscaler_mean.to(device)\n",
    "Xscaler_std = Xscaler_std.to(device)\n",
    "\n",
    "A_element = A_element.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can generate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(n_in, 100)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(100, 100)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(100, n_out)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class _ODEFunc(nn.Module):\n",
    "    \"\"\" Continuous surrogate dynamic system model\n",
    "    \"\"\"\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.module(x)\n",
    "\n",
    "\n",
    "class NeuralODE(nn.Module):\n",
    "    \"\"\" Neural ODE Net: using torchdiffeq package (Chen et al. NeurIPS 2018)\n",
    "    \"\"\"\n",
    "    def __init__(self, solver: str = 'dopri5', integration_time=[0, 1]):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.odefunc = _ODEFunc(ANN())\n",
    "        self.solver = solver\n",
    "        # self.use_adjoint = adjoint\n",
    "        self.integration_time = torch.tensor(integration_time, dtype=torch.float64)      \n",
    "\n",
    "    def forward(self, x: torch.Tensor, adjoint: bool = True, integration_time=None, rtol=1e-7, atol=1e-9, inf_solver=None):\n",
    "        \n",
    "        integration_time = self.integration_time if integration_time is None else integration_time\n",
    "        integration_time = integration_time.to(x.device)\n",
    "        # method to solve the neuralODE by torchdiffeq\n",
    "        ode_method =  tdf.odeint_adjoint if adjoint else tdf.odeint\n",
    "        solver = inf_solver if inf_solver else self.solver\n",
    "        out = ode_method(\n",
    "              self.odefunc, x, integration_time, rtol=rtol,\n",
    "              atol=atol, method=solver)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is then instantiated and transferred to the GPU if present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_node = NeuralODE(solver=\"rk4\")\n",
    "print(model_node)\n",
    "\n",
    "# Put model on GPU\n",
    "model_node = model_node.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_node.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_training_loop(X_train, X_val, Y_train, Y_val, integration_times, loss_fn, optimizer, n_epochs, model, log_transform):\n",
    "\n",
    "    # Array to store the loss and validation loss\n",
    "    loss_list = np.empty(n_epochs)\n",
    "    val_loss_list = np.empty(n_epochs//10)\n",
    "\n",
    "    epochs = np.arange(n_epochs)\n",
    "    epochs_small = epochs[::10]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # Training parameters\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "\n",
    "            Xbatch = X_train[i:i+batch_size,:]\n",
    "            Ybatch = Y_train[i:i+batch_size,:,:]\n",
    "\n",
    "            Ypred = model_node(Xbatch, integration_time=integration_times)\n",
    "            Ypred = torch.transpose(Ypred,0,1)\n",
    "            Ypred = torch.transpose(Ypred,1,2)\n",
    "            \n",
    "            loss = loss_fn(Ypred, Ybatch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_list[epoch] = loss\n",
    "\n",
    "        # Computing validation loss and mass conservation metric (only every 10 epochs as it is expensive)\n",
    "        if epoch%10==0:\n",
    "            model.eval()  # evaluation mode\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # VALIDATION LOSS\n",
    "                y_val_pred = model_node(X_val, integration_time=integration_times)\n",
    "                y_val_pred = torch.transpose(y_val_pred,0,1)\n",
    "                y_val_pred = torch.transpose(y_val_pred,1,2)\n",
    "\n",
    "                val_loss = loss_fn(y_val_pred, Y_val)\n",
    "\n",
    "            model.train()   # Back to training mode\n",
    "            val_loss_list[epoch//10] = val_loss\n",
    "\n",
    "        print(f\"Finished epoch {epoch}\")\n",
    "        print(f\"    >> Loss: {loss}\")\n",
    "        if epoch%10==0:\n",
    "            print(f\"    >> Validation loss: {val_loss}\")\n",
    "\n",
    "    return epochs, epochs_small, loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "epochs, epochs_small, loss_list, val_loss_list = main_training_loop(X_train, X_val, Y_train, Y_val, integration_times, loss_fn, optimizer, n_epochs, model_node, log_transform)\n",
    "end_time = time.perf_counter()\n",
    "print(f\" TRAINING DURATION: {end_time-start_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a function to analyze the training. We plot:\n",
    "\n",
    "+ The training and validation losses\n",
    "\n",
    "+ The evolution of $\\sum_{k=1}^{N_S} Y_k$ (mean, min and max).\n",
    "\n",
    "+ The elements conservation by plotting $100\\times\\delta Y_e$ for each element (C, H, O and N). The factor $100$ enables to get an error in \\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[12,:]\n",
    "y = Y_train[12,:]\n",
    "\n",
    "y_pred = model_node(x, integration_time=integration_times)\n",
    "y_pred = torch.transpose(y_pred,0,1)\n",
    "\n",
    "l = loss_fn(y,y_pred)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs, epochs_small, loss_list, val_loss_list):\n",
    "\n",
    "    # LOSSES\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(epochs, loss_list, color=\"k\", label=\"Training\")\n",
    "    ax.plot(epochs_small, val_loss_list, color=\"r\", label = \"Validation\")\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(epochs, epochs_small, loss_list, val_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the Pytorch model in the case folder for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_node.state_dict(), os.path.join(folder,\"pytorch_mlp.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the test initial conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_test = pd.read_csv(os.path.join(folder, \"sim_test.csv\"))\n",
    "\n",
    "n_sim = df_sim_test.shape[0]\n",
    "print(f\"There are {n_sim} test simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_simulations(dt):\n",
    "\n",
    "    list_test_results = []\n",
    "\n",
    "    fails = 0\n",
    "    for i, row in df_sim_test.iterrows():\n",
    "\n",
    "        phi_ini = row['Phi']\n",
    "        temperature_ini = row['T0']\n",
    "\n",
    "        print(f\"Performing test computation for phi={phi_ini}; T0={temperature_ini}\")\n",
    "\n",
    "        df_exact, df_nn, fail = compute_nn_cantera_0D_homo(device, model_node, Xscaler, Xscaler, phi_ini, temperature_ini, dt, dtb_params, A_element.detach().cpu().numpy(), 1, None, True)\n",
    "\n",
    "        fails += fail\n",
    "\n",
    "        list_test_results.append((df_exact, df_nn))\n",
    "\n",
    "\n",
    "    print(f\"dt={dt}:Total number of simulations which crashed: {fails}\")\n",
    "\n",
    "    return list_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_list = [0.1e-6, 0.2e-6, 0.4e-6, 0.6e-6, 0.8e-6, 1e-6, 1.2e-6, 1.4e-6, 1.6e-6, 1.8e-6, 2.0e-6]\n",
    "dt_list = [1.0e-7, 2.0e-7, 3.0e-7]\n",
    "dict_test_res = {}\n",
    "\n",
    "for dt in dt_list:\n",
    "\n",
    "     print(f\"RUNNING SIMULATIONS FOR DT={dt}\")\n",
    "     dict_test_res[dt] = run_test_simulations(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function to plot a given simulation, for a given dt: (in *dt_list*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_sim(i_sim, dt, dict_test_res, spec_to_plot):\n",
    "\n",
    "    df_exact =  dict_test_res[dt][i_sim][0]\n",
    "    df_nn =  dict_test_res[dt][i_sim][1]\n",
    "\n",
    "    # Temperature \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(df_exact['Time'], df_exact['Temperature'], color='k')\n",
    "    ax.plot(df_nn['Time'], df_nn['Temperature'], color='b')\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(\"T [K]\")\n",
    "\n",
    "    # Species (normal)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(df_exact['Time'], df_exact[spec_to_plot], color='k')\n",
    "    ax.plot(df_nn['Time'], df_nn[spec_to_plot], color='b')\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(f\"{spec_to_plot} [-]\")\n",
    "\n",
    "    # Species (log)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(df_exact['Time'], np.log(df_exact[spec_to_plot]), color='k')\n",
    "    ax.plot(df_nn['Time'], np.log(df_nn[spec_to_plot]), color='b')\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(f\"{spec_to_plot} [-]\")\n",
    "\n",
    "    # Sum of Yk\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df_nn['Time'], df_nn['SumYk'], color='b')\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(\"$\\sum Y_k$ [-]\")\n",
    "\n",
    "    # Elements\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "    ax1.plot(df_nn['Time'], df_nn['Y_C'], color='b')\n",
    "    ax2.plot(df_nn['Time'], df_nn['Y_H'], color='b')\n",
    "    ax3.plot(df_nn['Time'], df_nn['Y_O'], color='b')\n",
    "    ax4.plot(df_nn['Time'], df_nn['Y_N'], color='b')\n",
    "    ax1.set_ylabel(\"$Y_C$\")\n",
    "    ax2.set_ylabel(\"$Y_H$\")\n",
    "    ax3.set_ylabel(\"$Y_O$\")\n",
    "    ax4.set_ylabel(\"$Y_N$\")\n",
    "    ax3.set_xlabel(\"Time [s]\")\n",
    "    ax4.set_xlabel(\"Time [s]\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1e-7\n",
    "i_sim = 50\n",
    "spec_to_plot = \"H2\"\n",
    "plot_results_sim(i_sim, dt, dict_test_res, spec_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute fitness between two simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness(list_test_results):\n",
    "\n",
    "    # Results will be stored in data_errors array.\n",
    "    # The first column corresponds to errors on temperature\n",
    "    # The next n_out columns correspond to errors on species mass fractions\n",
    "    # The last column corresponds to the mean error\n",
    "    data_errors = np.empty([n_sim, n_out+2]) \n",
    "\n",
    "    for i_sim in range(n_sim):\n",
    "\n",
    "        df_exact = list_test_results[i_sim][0]\n",
    "        df_nn = list_test_results[i_sim][1]\n",
    "\n",
    "        # Removing undesired variables\n",
    "        df_exact = df_exact.drop('Time', axis=1)\n",
    "        df_nn = df_nn.drop([\"Time\",\"SumYk\", \"Y_C\", \"Y_H\", \"Y_O\", \"Y_N\"], axis=1)\n",
    "\n",
    "        # Applying log\n",
    "        if log_transform:\n",
    "\n",
    "            df_exact[df_exact < threshold] = threshold\n",
    "            df_nn[df_nn < threshold] = threshold\n",
    "\n",
    "            df_exact.iloc[:, 1:] = np.log(df_exact.iloc[:, 1:])\n",
    "            df_nn.iloc[:, 1:] = np.log(df_nn.iloc[:, 1:])\n",
    "\n",
    "        # Scaling\n",
    "        data_exact_scaled = (df_exact-Xscaler.mean)/(Xscaler.std+1.0e-7)\n",
    "        data_nn_scaled = (df_nn-Xscaler.mean)/(Xscaler.std+1.0e-7)\n",
    "\n",
    "        diff_exact_nn = np.abs((data_nn_scaled-data_exact_scaled)/data_exact_scaled)\n",
    "\n",
    "        diff_exact_nn = diff_exact_nn.mean(axis=0)\n",
    "\n",
    "        M = diff_exact_nn.mean()\n",
    "\n",
    "        print(f\"Simulation {i_sim} error M = {M}\")\n",
    "\n",
    "        data_errors[i_sim, :n_out+1] = diff_exact_nn\n",
    "        data_errors[i_sim, n_out+1] = M\n",
    "\n",
    "\n",
    "    return data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_errors = {}\n",
    "for dt in dt_list:\n",
    "    data_errors[dt] = compute_fitness(dict_test_res[dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the mean and std error for each dt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_errors_mean = np.empty(len(dt_list))\n",
    "data_errors_std = np.empty(len(dt_list))\n",
    "\n",
    "for i, dt in enumerate(dt_list):\n",
    "    data_errors_mean[i] = data_errors[dt][:,-1].mean()\n",
    "    data_errors_std[i] = data_errors[dt][:,-1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(dt_list, data_errors_mean, color=\"k\", marker=\"o\")\n",
    "\n",
    "ax.set_xlabel(\"dt [s]\", fontsize=14)\n",
    "ax.set_ylabel(\"Error [%]\", fontsize=14)\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
